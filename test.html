<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Audio Analyzer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        #transcript, .response-area {
            width: 100%;
            height: 200px;
            margin-top: 0px;
            font-size: 16px;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
        }
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        .status-indicator.active {
            background-color: #FF0000;
            animation: pulse 1.5s infinite;
        }
        .status-indicator.inactive {
            background-color: #CCCCCC;
        }
        #permissionInfo {
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            margin: 10px 0;
            display: none;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body>
    <h1>Real-time Audio Analyzer</h1>
    
    <div id="permissionInfo">
        <p><strong>Microphone access is required.</strong> Please allow microphone access when prompted.</p>
        <p>If you denied permission previously and want to enable it:</p>
        <ol>
            <li>Click the lock/info icon in your browser's address bar</li>
            <li>Find the microphone settings and change to "Allow"</li>
            <li>Refresh this page</li>
        </ol>
    </div>
    
    <div>
        <button id="startButton">Start Transcription</button>
        <button id="stopButton" disabled>Stop Transcription</button>
        <button onclick="copyTranscript()">Copy Transcript</button>
        <button onclick="document.getElementById('transcript').value='';">Clear Transcript</button>
        <span id="status">
            <span class="status-indicator inactive" id="statusIndicator"></span>
            <span id="statusText">Not recording</span>
        </span>
    </div>

    <BR>
    
    <input type="checkbox" id="showInterim" checked hidden>

    <div class="control-group">
        <label for="confidenceThreshold">Confidence Threshold:</label>
        <input type="range" id="confidenceThreshold" min="0.00" max="1" step="0.05" value="0.00">
        <span id="confidenceValue">0.00</span>
        <span class="tooltip">Higher values mean only more confident transcriptions are shown</span>
    </div>
    <BR>
    <label>AI Model</label>
    <select id="modelSelect" class="select" width="100%">
    </select>
     
    <label>AI Analysis Time Delay</label>
    <select id="analysis_time_delay" class="select" width="100%">
        <option value="10000">10 Seconds</option>
        <option value="30000" selected>30 Seconds</option>
        <option value="60000">1 Minute</option>
        <option value="3600000">1 Hour</option>
    </select>
     
    <label for="language">Language</label>
    <select id="language" name="language">
        <option value="af">Afrikaans</option>
        <option value="sq">Albanian</option>
        <option value="am">Amharic</option>
        <option value="ar">Arabic</option>
        <option value="hy">Armenian</option>
        <option value="eu">Basque</option>
        <option value="bn">Bengali</option>
        <option value="bs">Bosnian</option>
        <option value="bg">Bulgarian</option>
        <option value="ca">Catalan</option>
        <option value="zh-CN">Chinese (Simplified)</option>
        <option value="zh-TW">Chinese (Traditional)</option>
        <option value="hr">Croatian</option>
        <option value="cs">Czech</option>
        <option value="da">Danish</option>
        <option value="nl">Dutch</option>
        <option value="en" selected>English</option>
        <option value="et">Estonian</option>
        <option value="fi">Finnish</option>
        <option value="fr">French</option>
        <option value="ka">Georgian</option>
        <option value="de">German</option>
        <option value="el">Greek</option>
        <option value="gu">Gujarati</option>
        <option value="ht">Haitian Creole</option>
        <option value="he">Hebrew</option>
        <option value="hi">Hindi</option>
        <option value="hu">Hungarian</option>
        <option value="is">Icelandic</option>
        <option value="id">Indonesian</option>
        <option value="ga">Irish</option>
        <option value="it">Italian</option>
        <option value="ja">Japanese</option>
        <option value="jw">Javanese</option>
        <option value="kn">Kannada</option>
        <option value="kk">Kazakh</option>
        <option value="km">Khmer</option>
        <option value="ko">Korean</option>
        <option value="ku">Kurdish (Kurmanji)</option>
        <option value="lv">Latvian</option>
        <option value="lt">Lithuanian</option>
        <option value="mk">Macedonian</option>
        <option value="ms">Malay</option>
        <option value="ml">Malayalam</option>
        <option value="mr">Marathi</option>
        <option value="mn">Mongolian</option>
        <option value="ne">Nepali</option>
        <option value="no">Norwegian</option>
        <option value="ps">Pashto</option>
        <option value="fa">Persian</option>
        <option value="pl">Polish</option>
        <option value="pt">Portuguese</option>
        <option value="pa">Punjabi</option>
        <option value="ro">Romanian</option>
        <option value="ru">Russian</option>
        <option value="sr">Serbian</option>
        <option value="si">Sinhala</option>
        <option value="sk">Slovak</option>
        <option value="sl">Slovenian</option>
        <option value="es">Spanish</option>
        <option value="sw">Swahili</option>
        <option value="sv">Swedish</option>
        <option value="ta">Tamil</option>
        <option value="te">Telugu</option>
        <option value="th">Thai</option>
        <option value="tr">Turkish</option>
        <option value="uk">Ukrainian</option>
        <option value="ur">Urdu</option>
        <option value="uz">Uzbek</option>
        <option value="vi">Vietnamese</option>
        <option value="cy">Welsh</option>
        <option value="xh">Xhosa</option>
        <option value="yi">Yiddish</option>
        <option value="yo">Yoruba</option>
        <option value="zu">Zulu</option>
    </select>

    <BR><BR>
    Raw Transcript
    <textarea id="transcript" readonly></textarea>
    
    <div class="interim-container">
        <h4>Interim Results</h4>
        <div id="interimDisplay" class="interim-text"></div>
    </div>

    <h2>AI Analysis</h2>
    <button onclick="sendToAI(document.getElementById('transcript').value);">Analyze Now</button>

    <BR>
    <BR>
    <label id="timeToUpdate">AI API Response</label>
    <textarea id="aiAPIResponse" class="response-area" readonly></textarea>
    <BR>
    <label>Analyzed Transcript</label>
    <textarea id="fullTranscript" class="response-area" readonly></textarea>
    <BR>
    <label>Current Idea</label>
    <textarea id="current_idea" class="response-area" readonly></textarea>
    <BR>
    <label>Summary</label>
    <textarea id="summary" class="response-area" readonly></textarea>
    <BR>
    <label>Secrets</label>
    <textarea id="secrets" class="response-area" readonly></textarea>
    <BR>
    <label>Contradictions</label>
    <textarea id="contradictions" class="response-area" readonly></textarea>
    <BR>
    <label>Intent</label>
    <textarea id="intent" class="response-area" readonly></textarea>
    <BR>
    <label>Expected Response</label>
    <textarea id="expectedResponse" class="response-area" readonly></textarea>
    <BR>
    <label>Reward</label>
    <textarea id="reward" class="response-area" readonly></textarea>
    
    <script>
        // Global variables for speech recognition
        let recognition;
        let isRecognizing = false;
        let lastRequestTime = 0;
        let recognitionPaused = false;
        let lastTranscript = '';
        let restartAttempts = 0;
        const maxRestartAttempts = 10;
        let restartDelay = 1000;
        let watchdogTimer = null;
        let lastChatTime = Date.now();
        let micPermissionState = 'unknown';

        // Check if the browser supports speech recognition
        const supportsSpeechRecognition = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
        
        if (!supportsSpeechRecognition) {
            alert('Your browser does not support the Web Speech API. Please use Chrome, Edge, or Safari.');
            document.getElementById('startButton').disabled = true;
        }

        // Fixed sleep function with Promise return
        function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }

        // Improved watchdog timer
        async function startWatchdog() {
            if (watchdogTimer) {
                clearInterval(watchdogTimer);
            }

            watchdogTimer = setInterval(async () => {
                try {
                    const remainingTime = document.getElementById('analysis_time_delay').value - (Date.now() - lastRequestTime);
                    document.getElementById("timeToUpdate").innerText = `AI API Response (${Math.max(0, remainingTime)}ms)`;

                    if (isRecognizing && !recognitionPaused) {
                        const timeSinceLastActivity = Date.now() - lastChatTime;
                        
                        // Only restart after 15 seconds of inactivity (increased from 7s)
                        if (timeSinceLastActivity > 15000) {
                            console.log('Watchdog detected extended inactivity, restarting recognition');
                            lastChatTime = Date.now();
                            await restartRecognition();
                        }
                    }
                } catch (e) {
                    console.error('Watchdog error:', e);
                }
            }, 1000); // Check every second instead of 100ms
        }

        function stopWatchdog() {
            if (watchdogTimer) {
                clearInterval(watchdogTimer);
                watchdogTimer = null;
            }
        }

        function copyTranscript() {
            const copyText = document.getElementById("transcript");
            copyText.select();
            copyText.setSelectionRange(0, 99999);
            navigator.clipboard.writeText(copyText.value);
        }

        // Improved restart function with better state management
        async function restartRecognition() {
            if (!isRecognizing || recognitionPaused) return;
            
            console.log('Attempting to restart recognition...');
            updateStatus('Restarting...', true);
            
            try {
                // Stop current recognition if it exists
                if (recognition) {
                    recognition.onend = null; // Remove handler to prevent loop
                    recognition.onerror = null;
                    recognition.stop();
                    await sleep(500); // Short delay before starting new instance
                }
                
                // Only restart if we're still supposed to be recognizing
                if (isRecognizing && !recognitionPaused) {
                    initializeRecognition();
                }
            } catch (e) {
                console.error('Restart error:', e);
                updateStatus('Error restarting', false);
                
                // Try again with increasing delay
                restartDelay = Math.min(restartDelay * 2, 10000); // Max 10s delay
                setTimeout(() => restartRecognition(), restartDelay);
            }
        }

        // Enhanced permission checking
        async function checkMicrophonePermission() {
            try {
                if (!navigator.permissions) {
                    return 'unknown';
                }
                
                const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
                micPermissionState = permissionStatus.state;
                
                permissionStatus.onchange = () => {
                    micPermissionState = permissionStatus.state;
                    updatePermissionUI();
                    
                    if (micPermissionState === 'granted' && recognitionPaused) {
                        recognitionPaused = false;
                        startTranscription();
                    }
                };
                
                updatePermissionUI();
                return micPermissionState;
            } catch (error) {
                console.error('Permission check error:', error);
                return 'unknown';
            }
        }

        function updatePermissionUI() {
            const permissionInfo = document.getElementById('permissionInfo');
            
            switch(micPermissionState) {
                case 'granted':
                    permissionInfo.style.display = 'none';
                    document.getElementById('startButton').disabled = false;
                    break;
                case 'denied':
                    permissionInfo.style.display = 'block';
                    document.getElementById('startButton').disabled = true;
                    break;
                case 'prompt':
                    permissionInfo.style.display = 'block';
                    document.getElementById('startButton').disabled = false;
                    break;
                default:
                    permissionInfo.style.display = 'none';
                    document.getElementById('startButton').disabled = false;
            }
        }

        // Optimized transcript processing
        function processTranscript(newText) {
            const transcriptElement = document.getElementById('transcript');
            const currentValue = transcriptElement.value;
            
            if (currentValue.length > 10000) {
                transcriptElement.value = currentValue.substring(currentValue.length - 8000);
            }
            
            transcriptElement.value += newText;
            transcriptElement.scrollTop = transcriptElement.scrollHeight;
        }

        function startTranscription() {
            if (!supportsSpeechRecognition) {
                alert('Your browser does not support the Web Speech API.');
                return;
            }

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    stream.getTracks().forEach(track => track.stop());
                    micPermissionState = 'granted';
                    updatePermissionUI();
                    initializeRecognition();
                })
                .catch(error => {
                    console.error('Microphone permission error:', error);
                    
                    if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                        micPermissionState = 'denied';
                    } else {
                        micPermissionState = 'prompt';
                    }
                    
                    updatePermissionUI();
                    recognitionPaused = true;
                    
                    if (micPermissionState === 'prompt') {
                        initializeRecognition();
                    }
                });
        }

        function initializeRecognition() {
            // Stop any existing recognition
            if (recognition) {
                recognition.onend = null;
                recognition.onerror = null;
                recognition.stop();
            }
            
            isRecognizing = false;
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = document.getElementById('language').value;

            const showInterim = document.getElementById('showInterim').checked;
            const confidenceThreshold = parseFloat(document.getElementById('confidenceThreshold').value || 0);

            recognition.onresult = function(event) {
                lastChatTime = Date.now();
                
                let newTranscript = '';
                let interimTranscript = '';
                lastTranscript = document.getElementById('transcript').value.trim();

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const result = event.results[i];
                    const confidence = result[0].confidence;
                    
                    if (confidence < confidenceThreshold) continue;
                    
                    if (result.isFinal) {
                        let recognizedPhrase = result[0].transcript.trim();
                        if (!recognizedPhrase) continue;

                        const lastFewLines = lastTranscript.split('\n').slice(-3).join('\n');
                        if (!lastFewLines.includes(recognizedPhrase)) {
                            newTranscript += recognizedPhrase + '\n';
                        }
                    } else if (showInterim) {
                        let recognizedPhrase = result[0].transcript.trim();
                        if (recognizedPhrase) {
                            interimTranscript += recognizedPhrase + ' ';
                        }
                    }
                }

                if (newTranscript) {
                    processTranscript(newTranscript);
                    restartAttempts = 0;
                    restartDelay = 1000;
                }
                
                if (showInterim && document.getElementById('interimDisplay')) {
                    document.getElementById('interimDisplay').textContent = interimTranscript;
                }

                if (Date.now() - lastRequestTime > document.getElementById('analysis_time_delay').value) {
                    lastRequestTime = Date.now();
                    sendToAI(document.getElementById('transcript').value);
                }
            };

            recognition.onerror = function(event) {
                console.error('Speech recognition error:', event.error);
                
                if (event.error === 'no-speech') {
                    restartRecognition();
                } else if (event.error === 'audio-capture') {
                    updateStatus('Microphone error', false);
                    setTimeout(() => restartRecognition(), restartDelay);
                } else if (event.error === 'network') {
                    updateStatus('Network error, retrying...', false);
                    setTimeout(() => restartRecognition(), restartDelay);
                    restartDelay = Math.min(restartDelay * 2, 30000);
                } else if (event.error === 'not-allowed') {
                    updateStatus('Microphone access denied', false);
                    micPermissionState = 'denied';
                    updatePermissionUI();
                    recognitionPaused = true;
                } else {
                    restartRecognition();
                }
            };

            recognition.onend = function() {
                console.log('Recognition ended normally');
                if (isRecognizing && !recognitionPaused) {
                    console.log('Auto-restarting recognition after normal end');
                    setTimeout(() => restartRecognition(), 500);
                }
            };

            try {
                recognition.start();
                console.log('Speech recognition started');
                isRecognizing = true;
                recognitionPaused = false;
                document.getElementById('startButton').disabled = true;
                document.getElementById('stopButton').disabled = false;
                updateStatus('Recording...', true);
                restartAttempts = 0;
                restartDelay = 1000;
                startWatchdog();
                lastRequestTime = Date.now();
            } catch (e) {
                console.error('Error starting recognition:', e);
                alert('Failed to start speech recognition. Please reload the page and try again.');
                updateStatus('Error starting', false);
            }
        }

        function stopTranscription() {
            if (recognition) {
                recognition.onend = null;
                recognition.stop();
            }
            
            isRecognizing = false;
            recognitionPaused = false;
            document.getElementById('startButton').disabled = false;
            document.getElementById('stopButton').disabled = true;
            updateStatus('Not recording', false);
            stopWatchdog();
        }

        async function updateStatus(message, isActive) {
            const statusText = document.getElementById('statusText');
            const statusIndicator = document.getElementById('statusIndicator');
            
            statusText.textContent = message;
            
            if (isActive) {
                statusIndicator.classList.remove('inactive');
                statusIndicator.classList.add('active');
            } else {
                statusIndicator.classList.remove('active');
                statusIndicator.classList.add('inactive');
            }
        }

        async function sendToAI(transcript) {
            function estimateTokens(message) {
                return Math.ceil(message.split(/\s+/).length / 1.33);
            }

            while (estimateTokens(transcript) > 1000) {
                transcript = transcript.substring(1);
            }

            if (!transcript.trim()) return;
            
            updateStatus('Sending to AI...', true);
            
            fetch("https://proxy.small-recipe-9582.workers.dev/", {
                method: "POST",
                headers: {
                    "accept-language": "en-US,en;q=0.9",
                    "authorization": "Bearer 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",
                    "content-type": "application/json"
                },
                referrer: "https://www.avemariacloud.com/",
                referrerPolicy: "strict-origin-when-cross-origin",
                body: JSON.stringify({
                    model: document.getElementById("modelSelect").value,
                    messages: [
                        {
                            role: "system",
                            content: `I am interested in analyzing some transcription data

I am interested in creating a full word for word transcript, not a summary or analysis, of what has been said based on the transcription data.

I am interested in a single sentence summary of the most recently discussed idea. (Current_Idea).

I am interested in a three sentence summary of the entire transcript (Full_Summary).

I am interested in detecting secrets and/or contradictions. I am interested in a single sentence response.

I am interested in detecting the intent of the speaker. I am interested in a single sentence response.

I am interested in detecting the ideal response that this person is expecting. I am interested in a response that is consistent with a conversation. I am interested in a single sentence response.

I am interested in some sort of intellectual reward from this speech. I am interested in a single sentence response.

Respond in JSON with the labels: Full_Transcript, Current_Idea, Full_Summary, Secrets, Contradictions, Intent, Expected_Response, Reward.`
                        },
                        {
                            role: "user",
                            content: transcript
                        }
                    ],
                    response_format: { type: "json_object" }
                }),
                mode: "cors"
            })
            .then(response => response.json())
            .then(data => {
                displayResponse(data);
                updateStatus(isRecognizing ? 'Recording...' : 'Not recording', isRecognizing);
            })
            .catch(error => {
                console.error('Error:', error);
                updateStatus(isRecognizing ? 'Recording...' : 'Not recording', isRecognizing);
            });
        }

        function displayResponse(data) {
            const now = new Date();
            const hours = now.getHours().toString().padStart(2, '0');
            const minutes = now.getMinutes().toString().padStart(2, '0');
            const seconds = now.getSeconds().toString().padStart(2, '0');
            const timeString = `${hours}:${minutes}:${seconds}`;

            data = data['choices'][0]['message']['content'];
            document.getElementById("aiAPIResponse").value = data;
            data = JSON.parse(data);

            document.getElementById("fullTranscript").value = data.Full_Transcript;
            document.getElementById("current_idea").value = "[" + timeString + "] " + data.Current_Idea + "\n\n" + document.getElementById("current_idea").value;
            document.getElementById("summary").value = "[" + timeString + "] " + data.Full_Summary + "\n\n" + document.getElementById("summary").value;
            document.getElementById("secrets").value = "[" + timeString + "] " + data.Secrets + "\n\n" + document.getElementById("secrets").value;
            document.getElementById("contradictions").value = "[" + timeString + "] " + data.Contradictions + "\n\n" + document.getElementById("contradictions").value;
            document.getElementById("intent").value = "[" + timeString + "] " + data.Intent + "\n\n" + document.getElementById("intent").value;
            document.getElementById("expectedResponse").value = "[" + timeString + "] " + data.Expected_Response + "\n\n" + document.getElementById("expectedResponse").value;
            document.getElementById("reward").value = "[" + timeString + "] " + data.Reward + "\n\n" + document.getElementById("reward").value;
        }

        window.addEventListener('DOMContentLoaded', function() {
            checkMicrophonePermission();
            
            document.getElementById('startButton').addEventListener('click', startTranscription);
            document.getElementById('stopButton').addEventListener('click', stopTranscription);
            
            document.getElementById('confidenceValue').textContent = document.getElementById('confidenceThreshold').value;
            
            document.getElementById('confidenceThreshold').addEventListener('input', function() {
                document.getElementById('confidenceValue').textContent = this.value;
            });
            
            const selectedLanguage = localStorage.getItem('selectedLanguage');
            if (selectedLanguage) {
                document.getElementById('language').value = selectedLanguage;
            }
            
            document.getElementById('language').addEventListener('change', function() {
                localStorage.setItem('selectedLanguage', this.value);
                if (isRecognizing) {
                    restartRecognition(true);
                }
            });
        });
    </script>

    <BR>
    <BR>

<div id="informationFooter" style="padding-left: 4em; padding-right: 4em;"></div>
<script src="https://www.avemariacloud.com/generic-loader.js"></script>

</body>
</html>
