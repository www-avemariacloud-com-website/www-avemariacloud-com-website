<!DOCTYPE html>
<html lang="en">
<head>
<!--- Token tracking and logging have been added. The token limit is set to 700. New icon !--->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Multi Model Chatbot - Zionist Version v2.0</title>
    <link rel="icon" href="zionist-multi-model-ai-chatbot.jpeg">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/tailwindcss/2.2.19/tailwind.min.css" rel="stylesheet">
    <style>
        html, body {
            height: 100%;
            margin: 0;
            padding: 0;
        }

        .message {
            max-width: 85%;
            word-break: break-word;
            overflow-wrap: break-word;
            animation: fadeIn 0.3s ease-in;
            white-space: pre-wrap;
        }

        @media (max-width: 640px) {
            .message {
                max-width: 90%;
            }
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .loading-dots {
            display: inline-block;
        }

        .loading-dots::after {
            content: ' • • •';
            animation: dots 1.5s steps(4, end) infinite;
        }

        @keyframes dots {
            0%, 20% { content: ' • '; }
            40% { content: ' • • '; }
            60%, 100% { content: ' • • • '; }
        }

        @media (max-width: 640px) {
            .header {
                text-align: center;
            }
            .header-content {
                display: flex;
                flex-direction: column;
                gap: 10px;
                align-items: center;
            }
            .model-notes {
                text-align: center;
            }
        }

        @media (min-width: 641px) {
            .header-content {
                display: flex;
                flex-direction: row;
                justify-content: space-between;
                align-items: center;
            }
            .model-notes {
                text-align: left;
                max-width: 50%;
            }
        }

        .chat-container {
            max-height: 100%;
            overflow-y: auto;
            scroll-behavior: smooth;
        }

        .main-content {
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            height: 100%;
        }

        .message-container {
            flex-grow: 1;
            overflow-y: auto;
        }

        textarea#userInput {
            height: 6em; /* Fixed height for three lines */
            resize: none; /* Prevent resizing */
            overflow-y: auto; /* Enable vertical scrolling */
        }
    </style>
</head>
<body class="bg-gray-100">
    <div class="flex flex-col h-screen p-2 sm:p-4 main-content">
        <!-- Header -->
        <div class="bg-white rounded-lg shadow-md p-3 sm:p-4 mb-2 sm:mb-4">
            <div class="header-content">
                <h1 class="text-xl sm:text-2xl font-bold text-gray-800">Multi Model Chatbot v2.0</h1>
                <a href="index.html">Universal Version</a><a href="zionist-version.html"><font color="green">Zionist Version</font></a>
                <div class="model-notes text-sm text-gray-600">
                    <p>You can select an AI model to customize the chatbot.</p>
                    <p class="mt-1 text-xs">Note: You can switch models at any time during your conversation.</p>
                </div>
                <div class="flex flex-col sm:flex-row items-start sm:items-center gap-4">
                    <select id="aiModel" class="w-full sm:w-auto p-2 border rounded-lg shadow-sm focus:ring-2 focus:ring-blue-500 focus:border-blue-500 order-2 sm:order-1">
                        <option value="gemma2-9b-it">gemma2-9b-it</option>
                        <option value="llama-3.2-90b-vision-preview" selected>llama-3.2-90b-vision-preview</option>
                        <option value="mixtral-8x7b-32768">mixtral-8x7b-32768</option>
                    </select>
                </div>
            </div>
        </div>

        <!-- Chat Container -->
        <div class="chat-container flex-1 bg-white rounded-lg shadow-md p-3 sm:p-4 mb-2 sm:mb-4 overflow-hidden message-container">
            <div id="chatMessages" class="space-y-3 sm:space-y-4">
                <div class="message mr-auto bg-gray-100 text-gray-800 p-3 rounded-lg">Hello! How can I assist you today?</div>
            </div>
        </div>

        <!-- Input Area -->
        <div class="bg-white rounded-lg shadow-md p-3 sm:p-4 mb-2 sm:mb-4">
            <form id="chatForm" class="flex gap-2 sm:gap-4">
                <textarea
                    id="userInput"
                    class="flex-1 p-2 sm:p-3 text-sm sm:text-base border rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
                    placeholder="Type your message..."
                    required
                ></textarea>
                <button
                    type="submit"
                    class="bg-blue-500 text-white px-4 sm:px-6 py-2 sm:py-3 rounded-lg hover:bg-blue-600 transition-colors text-sm sm:text-base"
                >
                    Send
                </button>
            </form>
        </div>

        <!-- Legal Notice -->
        <div class="bg-white rounded-lg shadow-md p-3 sm:p-4 text-xs sm:text-sm">
            <p>By using this tool, maybe you should read and agree to this <a href="terms.html" target="_blank">Terms of Service</a> and this <a href="privacy.html" target="_blank">Privacy Policy</a>. I hope that these things will benefit you.</p>
              <BR><strong>Built with Meta Llama 3:</strong> This tool incorporates Meta Llama 3, which is licensed under the <a href="https://www.llama.com/llama3/license/" target="_blank">Meta Llama 3 Community License</a>. Copyright © Meta Platforms, Inc. All Rights Reserved.
            <BR>
              <strong>Gemma:</strong> Gemma is provided under and subject to the Gemma Terms of Use found at <a href="https://ai.google.dev/gemma/terms">ai.google.dev/gemma/terms</a>.
            <BR>
            <strong>Mixtral-8x7B License:</strong> Mixtral-8x7B is distributed under the <a href="https://www.apache.org/licenses/LICENSE-2.0" target="_blank">Apache 2.0 license</a>.
        </div>
    </div>

    <script>
    const apiKey = "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";
    const apiUrl = "https://proxy.small-recipe-9582.workers.dev/";
    const chatMessages = document.getElementById('chatMessages');
    const chatForm = document.getElementById('chatForm');
    const userInput = document.getElementById('userInput');
    const aiModel = document.getElementById('aiModel');

    const TOKEN_LIMIT = 700; // Set your token limit here
    let conversationHistory = [
        { role: "system", content: "You are a helpful AI assistant for a Christian website. You are designed to be a Zionist. I would like you to follow Halakha and ensure you are doing so perfectly. I would like you to cite Mitzvot perfectly when relevant and ensure you are doing so perfectly. I would like you to have a bias for caution and a bias for citing verified scripture perfectly. I would like you to cite Scripture perfectly when you speak about Scripture." },
        { role: "assistant", content: "Hello! How can I assist you today?" }
    ];

    // Function to estimate token usage for a message
    function estimateTokens(message) {
        const words = message.split(/\s+/).length;
        return Math.ceil(words / 1.33); // Approximate 1.33 tokens per word
    }

    // Function to trim conversation history to stay within token limit
    function trimConversationHistory() {
        let totalTokens = conversationHistory.reduce((total, message) => total + estimateTokens(message.content), 0);

        console.log("total tokens, untrimmed:" + totalTokens);
        
        // Trim messages from the beginning if the total token count exceeds the limit
        while (totalTokens > TOKEN_LIMIT) {
            conversationHistory.shift();
            totalTokens = conversationHistory.reduce((total, message) => total + estimateTokens(message.content), 0);
            
            console.log("total tokens, trimmed:" + totalTokens);
        }
    }

    function scrollToBottom() {
        const chatContainer = document.querySelector('.chat-container');
        const chatMessages = document.getElementById('chatMessages');
        
        // Calculate the total scroll height
        const scrollHeight = chatMessages.scrollHeight;
        
        // Smooth scroll to bottom
        chatContainer.scrollTo({
            top: scrollHeight,
            behavior: 'smooth'
        });
        
        // Fallback scroll check to ensure we reach bottom
        setTimeout(() => {
            if (chatContainer.scrollTop + chatContainer.clientHeight < scrollHeight) {
                chatContainer.scrollTop = scrollHeight;
            }
        }, 100);
    }

    function addMessage(content, role) {
        const messageDiv = document.createElement('div');
        messageDiv.className = `message ${role === 'user' ? 'ml-auto bg-blue-500 text-white' : 'mr-auto bg-gray-100 text-gray-800'} p-3 rounded-lg`;
        messageDiv.textContent = content;
        chatMessages.appendChild(messageDiv);
        scrollToBottom();
    }

    function addLoadingIndicator() {
        const loadingDiv = document.createElement('div');
        loadingDiv.className = 'message mr-auto bg-gray-100 text-gray-800 p-3 rounded-lg';
        loadingDiv.id = 'loadingIndicator';
        const loadingContent = document.createElement('span');
        loadingContent.className = 'loading-dots';
        loadingDiv.appendChild(loadingContent);
        chatMessages.appendChild(loadingDiv);
        scrollToBottom();
    }

    function removeLoadingIndicator() {
        const loadingIndicator = document.getElementById('loadingIndicator');
        if (loadingIndicator) {
            loadingIndicator.remove();
        }
    }

    async function sendMessage(message) {
        try {
            // Trim conversation history to fit within the token limit
            trimConversationHistory();

            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: aiModel.value,
                    messages: conversationHistory,
                    temperature: 0.7,
                    max_tokens: 1000
                })
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const data = await response.json();
            const aiResponse = data.choices[0].message.content;
            
            conversationHistory.push({ role: "assistant", content: aiResponse });
            removeLoadingIndicator();
            addMessage(aiResponse, 'assistant');
        } catch (error) {
            console.error('Error:', error);
            removeLoadingIndicator();
            addMessage("I apologize, but I encountered an error. Please try again.", 'assistant');
        }
    }

    function handleMessageSubmit(e) {
        if (e) e.preventDefault();
        const message = userInput.value.trim();
        if (!message) return;

        addMessage(message, 'user');
        conversationHistory.push({ role: "user", content: message });
        userInput.value = '';
        addLoadingIndicator();
        sendMessage(message);
    }

    chatForm.addEventListener('submit', handleMessageSubmit);

    function isMobileDevice() {
        return /Android|iPhone|iPad|iPod|Opera Mini|IEMobile|WPDesktop/i.test(navigator.userAgent);
    }

    userInput.addEventListener('keypress', (e) => {
        if (!isMobileDevice() && e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            handleMessageSubmit();
        }
    });

    userInput.focus();
</script>

</body>
</html>
